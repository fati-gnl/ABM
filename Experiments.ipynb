{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUFp2vEpzTt4",
        "outputId": "73d0206f-8bc7-4879-f594-9cb2d97a9b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.0/192.0 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install mesa --quiet\n",
        "!pip install ipynb --quiet\n",
        "!pip install Axelrod --quiet\n",
        "!pip install SALib --quiet\n",
        "!pip install names-generator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import time\n",
        "import tqdm\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "from enum import Enum\n",
        "import names_generator\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from typing import List, Type, Tuple\n",
        "\n",
        "import mesa\n",
        "from mesa import Agent\n",
        "from mesa import Model\n",
        "from mesa.datacollection import DataCollector\n",
        "from mesa.time import BaseScheduler\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations, product"
      ],
      "metadata": {
        "id": "l4J2EEmCABB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x: np.ndarray, lambda_: float) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Calculate softmax of x, weighted by lambda.\n",
        "    This is logit equlibrium function https://en.wikipedia.org/wiki/Quantal_response_equilibrium#Logit_equilibrium\n",
        "    This function is implemented so it's numerically stable.\n",
        "    :param x: estimated payoffs for each action\n",
        "    :param lambda_: rationality factor. 0 - random\n",
        "    :return: computed softmax\n",
        "    \"\"\"\n",
        "    x = x * lambda_\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "\n",
        "def sample_action(utilities: np.ndarray, possible_actions: Type[Enum], lambda_: float) -> Enum:\n",
        "    \"\"\"\n",
        "    Sample action taking into considerations estimated utilities per each action.\n",
        "    :param utilities: per each action estimated utility will be treated as distribution\n",
        "    :param possible_actions: possible actions for this agent\n",
        "    :param lambda_: rationality factor. 0 - random\n",
        "    :return: action\n",
        "    \"\"\"\n",
        "    distribution = softmax(utilities, lambda_)\n",
        "    action = possible_actions(np.argmax(np.random.multinomial(1, distribution)))\n",
        "    return action\n",
        "\n",
        "\n",
        "class CitizenActions(Enum):\n",
        "    \"\"\"\n",
        "    Actions possible for citizen\n",
        "    \"\"\"\n",
        "    accept_complain = 0\n",
        "    accept_silent = 1\n",
        "    reject_complain = 2\n",
        "    reject_silent = 3\n",
        "\n",
        "\n",
        "class CopActions(Enum):\n",
        "    \"\"\"\n",
        "    Actions possible for cop\n",
        "    \"\"\"\n",
        "    bribe = 0\n",
        "    not_bribe = 1\n",
        "\n",
        "\n",
        "class CopMemoryInitial(Enum):\n",
        "    \"\"\"\n",
        "    The value for the Accepting bribe memory initialization. Depending on how Cop is we have different vals.\n",
        "    \"\"\"\n",
        "    Corrupt = 1.0\n",
        "    Indifferent = 0.5\n",
        "    Honest = 0.0\n",
        "\n",
        "\n",
        "class CitizenMemoryInitial(Enum):\n",
        "    \"\"\"\n",
        "    The value for how succesful is complaining. Depending on the system, citizen will have different experiences. Assuming that if system is honest they had nice memories.\n",
        "    \"\"\"\n",
        "    Corrupt = 0.0\n",
        "    Indifferent = 0.5\n",
        "    Honest = 1.0"
      ],
      "metadata": {
        "id": "zDrLrt4cABsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Corruption(Model):\n",
        "    def __init__(self,\n",
        "                 num_citizens=2500,\n",
        "                 num_cops=100,\n",
        "                 team_size=10,\n",
        "                 rationality_of_agents=10,  # 0 is random totally\n",
        "                 jail_time=4,\n",
        "                 prob_of_prosecution=0.7,  # ground truth\n",
        "                 memory_size=10,\n",
        "                 fine_amount=1.,  # don't change this in sensitivity analysis\n",
        "                 cost_complain=0.4,\n",
        "                 penalty_citizen_prosecution=0.,\n",
        "                 jail_cost_factor=0.5,\n",
        "                 # jail cost and jail_time should somehow relate to each other I think, but don't know how exactly\n",
        "                 cost_accept_mean_std=(0.2, 0.05),\n",
        "                 citizen_complain_memory_discount_factor=0.5,\n",
        "                 bribe_amount=0.5,\n",
        "                 moral_commitment_mean_std=(0.25, 0.1),\n",
        "                 initial_time_left_in_jail=0,  # don't think it's worth to change that\n",
        "                 initial_indifferent_corruption_honest_rate=(1.0, 0.0, 0.0),\n",
        "                 corruption_among_teams_spread=1.0,\n",
        "                 # rate of teams that should be getting the corrupted cops. 1 - all teams have the same amount(+-1 cop ofc)\n",
        "                 logger: bool = True,\n",
        "                 test_params=None,  # parameter that are tested in an experiment and should be saved in the file name\n",
        "                 ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        if logger:\n",
        "            if test_params is not None:\n",
        "\n",
        "                self.experiment_name = \"\"\n",
        "                dir_name = \"\"\n",
        "                for (param_name, param_value) in test_params.items():\n",
        "                    setting = param_name + \"_\" + str(param_value)\n",
        "                    self.experiment_name += setting + \"-\"\n",
        "                    dir_name += \"-\" + param_name\n",
        "                self.data_dir = Path(\"results\" + dir_name)\n",
        "                # remove last dash\n",
        "                self.experiment_name = self.experiment_name[:-1]\n",
        "            else:\n",
        "                # Create a random name for experiment and add date\n",
        "                now = datetime.now()  # current date and time\n",
        "                self.experiment_name = names_generator.generate_name() + \"_\" + now.strftime(\"%d_%m_%H_%M\")\n",
        "                self.data_dir = Path(\"results/\")\n",
        "            #print(\"Saving at: \", str(self.data_dir), \"Experiment name: \", self.experiment_name)\n",
        "\n",
        "\n",
        "        # saving everything, then it can be logged\n",
        "        self.bribe_amount = bribe_amount\n",
        "        self.initial_time_left_in_jail = initial_time_left_in_jail\n",
        "        self.cost_accept_mean_std = cost_accept_mean_std\n",
        "        self.moral_commitment_mean_std = moral_commitment_mean_std\n",
        "        self.citizen_complain_memory_discount_factor = citizen_complain_memory_discount_factor\n",
        "        self.prob_of_prosecution = prob_of_prosecution\n",
        "        self.memory_size = memory_size\n",
        "        self.cost_complain = cost_complain\n",
        "        self.penalty_citizen_prosecution = penalty_citizen_prosecution\n",
        "        self.fine_amount = fine_amount\n",
        "        self.rationality_of_agents = rationality_of_agents\n",
        "        self.num_citizens = num_citizens\n",
        "        self.num_cops = num_cops\n",
        "        assert self.num_cops <= self.num_citizens, \"There should be more citizens than cops!\"\n",
        "        # cops calculations\n",
        "        self.num_indifferent_cops = int(initial_indifferent_corruption_honest_rate[0] * num_cops)\n",
        "        self.num_corrupted_cops = int(initial_indifferent_corruption_honest_rate[1] * num_cops)\n",
        "        self.num_honest_cops = int(initial_indifferent_corruption_honest_rate[2] * num_cops)\n",
        "        self.num_honest_cops += self.num_cops - (self.num_corrupted_cops + self.num_honest_cops + self.num_indifferent_cops)\n",
        "\n",
        "        # citizen calculations\n",
        "        self.num_indifferent_citizens = int(initial_indifferent_corruption_honest_rate[0] * num_citizens)\n",
        "        self.num_corrupted_citizens = int(initial_indifferent_corruption_honest_rate[1] * num_citizens)\n",
        "        self.num_honest_citizens = int(initial_indifferent_corruption_honest_rate[2] * num_citizens)\n",
        "        self.num_honest_citizens += self.num_citizens - (\n",
        "                self.num_corrupted_citizens + self.num_honest_citizens + self.num_indifferent_citizens)\n",
        "\n",
        "        self.team_size = team_size\n",
        "        assert self.num_cops % self.team_size == 0, \\\n",
        "            f\"You need to set num of cops to be dividable by team size. Each team should have the same size! Your num_cops: {self.num_cops}, teamsize: {self.team_size}\"\n",
        "        self.number_of_teams = math.ceil(self.num_cops / self.team_size)\n",
        "\n",
        "        # how many iterations cop is inactive\n",
        "        self.jail_time = jail_time\n",
        "        # actual cost that cop takes into consideration in the utility function\n",
        "        self.jail_cost_factor = jail_cost_factor\n",
        "        self.jail_cost = self.jail_cost_factor * jail_time\n",
        "\n",
        "        assert sum(\n",
        "            [rate for rate in initial_indifferent_corruption_honest_rate]) == 1.0, \"Distribution should sum up to 1.\"\n",
        "\n",
        "        # Checking if the value isn't to small, if it is set it to minimum\n",
        "        self.corruption_among_teams_spread = corruption_among_teams_spread\n",
        "        self.number_of_corrupted_teams = math.ceil(max(corruption_among_teams_spread * self.number_of_teams,\n",
        "                                                       initial_indifferent_corruption_honest_rate[\n",
        "                                                           1] * num_cops / self.team_size))\n",
        "        # Initialise schedulers\n",
        "        self.schedule = BaseScheduler(self)\n",
        "        self.schedule_Cop = BaseScheduler(self)\n",
        "        self.init_agents()\n",
        "        # Data collector to be able to save the data\n",
        "        self.datacollector = self.get_server_data_collector()\n",
        "\n",
        "        # Divide the cops over a network of teams\n",
        "        self.create_network()\n",
        "\n",
        "        self.datacollector.collect(self)\n",
        "        \n",
        "\n",
        "        self.logger = logger\n",
        "        # if self.logger:\n",
        "        #     # Should be after all initializations as it saves all params!\n",
        "        #     self.init_logger()\n",
        "\n",
        "    def step(self):\n",
        "        self.cops_playing = [cop for cop in self.schedule_Cop.agents if cop.time_left_in_jail == 0]\n",
        "        self.citizens_playing = random.sample(self.schedule.agents, len(self.cops_playing))\n",
        "\n",
        "        self.schedule.step()\n",
        "        self.schedule_Cop.step()\n",
        "\n",
        "        self.datacollector.collect(self)\n",
        "        self.update_network()\n",
        "        # if self.logger:\n",
        "        #     self.log_data(self.schedule.steps)\n",
        "\n",
        "    def init_agents(self):\n",
        "        # Add agents to schedulers\n",
        "        for i in range(self.num_citizens):\n",
        "\n",
        "            # citizen_initial_prone_to_complain = citizen_initial_prone_to_complain\n",
        "            if i < self.num_indifferent_citizens:\n",
        "                # indifferent\n",
        "                citizen_initial_prone_to_complain = CitizenMemoryInitial.Indifferent.value\n",
        "            elif i < self.num_indifferent_citizens + self.num_corrupted_citizens:\n",
        "                citizen_initial_prone_to_complain = CitizenMemoryInitial.Corrupt.value\n",
        "            else:\n",
        "                citizen_initial_prone_to_complain = CitizenMemoryInitial.Honest.value\n",
        "\n",
        "            citizen = Citizen(i,\n",
        "                              self,\n",
        "                              cost_accept_mean_std=self.cost_accept_mean_std,\n",
        "                              prone_to_complain=citizen_initial_prone_to_complain,\n",
        "                              complain_memory_discount_factor=self.citizen_complain_memory_discount_factor)\n",
        "            self.schedule.add(citizen)\n",
        "        # needed for assigning to teams\n",
        "        self.lookup_corrupt_cops = defaultdict(list)\n",
        "        for i in range(self.num_cops):\n",
        "            if i < self.num_indifferent_cops:\n",
        "                # indifferent\n",
        "                accepted_bribe_memory_initial = CopMemoryInitial.Indifferent.value\n",
        "            elif i < self.num_indifferent_cops + self.num_honest_cops:\n",
        "                accepted_bribe_memory_initial = CopMemoryInitial.Honest.value\n",
        "            else:\n",
        "                accepted_bribe_memory_initial = CopMemoryInitial.Corrupt.value\n",
        "\n",
        "            cop = Cop(i,\n",
        "                      self,\n",
        "                      time_left_in_jail=self.initial_time_left_in_jail,\n",
        "                      accepted_bribe_memory_size=self.memory_size,\n",
        "                      bribe_amount=self.bribe_amount,\n",
        "                      moral_commitment_mean_std=self.moral_commitment_mean_std,\n",
        "                      accepted_bribe_memory_initial=accepted_bribe_memory_initial)\n",
        "            self.schedule_Cop.add(cop)\n",
        "            self.lookup_corrupt_cops[\n",
        "                \"corrupt\" if accepted_bribe_memory_initial == CopMemoryInitial.Corrupt.value else \"other\"].append(i)\n",
        "\n",
        "    def get_citizen(self):\n",
        "        \"\"\"\n",
        "        Get the citizen chosen citizens and give them to the cop.\n",
        "        :return: citizen\n",
        "        \"\"\"\n",
        "        citizen = random.sample(self.citizens_playing, 1)[0]\n",
        "        # remove the citizen so they don't get caught twice in the same iteration\n",
        "        self.citizens_playing.remove(citizen)\n",
        "        return citizen\n",
        "\n",
        "    def create_network(self):\n",
        "        \"\"\"\n",
        "        Create network of police officers. They form not intersecting groups of team_size.\n",
        "        The amount of bribing cops depend on the `initial_indifferent_corruption_honest_rate`\n",
        "         and how many in each team `corruption_among_teams_spread`.\n",
        "        NOTE: indifferent and honest cops are treated the same here. First corrupted cops are allocated and then non-corrupt.\n",
        "        They're allocated randomly. You can set indifferent rate or the honest rate to 0 and then be sure.\n",
        "        \"\"\"\n",
        "\n",
        "        # depending on this check rate of corruption in the team, maybe if none do it totally randomly?\n",
        "        if self.number_of_corrupted_teams == 0:\n",
        "            corrupt_cop_per_team = 0\n",
        "            surplas_modulo = 0\n",
        "        else:\n",
        "            corrupt_cop_per_team = int(self.num_corrupted_cops / self.number_of_corrupted_teams)\n",
        "            surplas_modulo = self.num_corrupted_cops % self.number_of_corrupted_teams\n",
        "        #corrupt_cop_per_team = int(self.num_corrupted_cops / self.number_of_corrupted_teams)\n",
        "        #  some teams might have to take the additional cops\n",
        "        # surplas_modulo = self.num_corrupted_cops % self.number_of_corrupted_teams\n",
        "\n",
        "        # Initialise the dictionaries to convert the cop_id to team name, and to convert team name to #cops in jail\n",
        "        self.id_team = defaultdict(str)\n",
        "        self.team_jailed = defaultdict(int)\n",
        "        random.shuffle(self.lookup_corrupt_cops[\"other\"])\n",
        "        # Corrupted teams first\n",
        "        for team_number in range(self.number_of_corrupted_teams):\n",
        "            team_name = \"team_\" + str(team_number)\n",
        "            self.team_jailed[team_name] = 0\n",
        "\n",
        "            number_of_corrupt_cops_in_this_team = corrupt_cop_per_team + (1 if team_number < surplas_modulo else 0)\n",
        "            # First allocate corrupted cops\n",
        "            for corrupted_cop in range(number_of_corrupt_cops_in_this_team):\n",
        "                cop_id = self.lookup_corrupt_cops[\"corrupt\"].pop()\n",
        "                self.id_team[cop_id] = team_name\n",
        "            # Allocate not corrupted cops\n",
        "            for other_cops in range(self.team_size - number_of_corrupt_cops_in_this_team):\n",
        "                cop_id = self.lookup_corrupt_cops[\"other\"].pop()\n",
        "                self.id_team[cop_id] = team_name\n",
        "        # Not Corrupted teams\n",
        "\n",
        "        for team_number in range(self.number_of_corrupted_teams, self.number_of_teams):\n",
        "            team_name = \"team_\" + str(team_number)\n",
        "            self.team_jailed[team_name] = 0\n",
        "            # Allocate not corrupted cops\n",
        "            for other_cops in range(self.team_size):\n",
        "                # random because some are indifferent and some are honest\n",
        "                indx = random.randint(0, len(self.lookup_corrupt_cops[\"other\"]) - 1)\n",
        "                cop_id = self.lookup_corrupt_cops[\"other\"].pop(indx)\n",
        "                self.id_team[cop_id] = team_name\n",
        "\n",
        "    def num_active_citizens(self):\n",
        "        return sum([1 for cit in self.schedule.agents if\n",
        "                    cit.action is not None])\n",
        "\n",
        "    def update_network(self):\n",
        "        \"\"\"\n",
        "        Update the current jail rate for each team.\n",
        "        \"\"\"\n",
        "        # Reset the #cops in jail for each team\n",
        "        for team in self.team_jailed:\n",
        "            self.team_jailed[team] = 0\n",
        "\n",
        "        # Update the #cops in jail for each team\n",
        "        for cop in self.schedule_Cop.agents:\n",
        "            team = self.id_team[cop.unique_id]\n",
        "            self.team_jailed[team] += 1 if cop.time_left_in_jail > 0 else 0\n",
        "\n",
        "    def init_logger(self):\n",
        "        \"\"\"\n",
        "        Logs data in the beginning. Model params and each agent params. Saves it self.log_path at init_params key.\n",
        "        \"\"\"\n",
        "\n",
        "        self.data_dir.mkdir(exist_ok=True)\n",
        "        self.log_path = Path(self.data_dir, self.experiment_name + '.json')\n",
        "        try:\n",
        "            os.remove(self.log_path)\n",
        "        except:\n",
        "            pass\n",
        "        name = 'iteration_0'\n",
        "        log_dict = self.get_log_data(name)\n",
        "\n",
        "        with open(self.log_path, 'a') as f:\n",
        "            json.dump(log_dict, f)\n",
        "            f.write(os.linesep)\n",
        "\n",
        "    def log_data(self, step):\n",
        "        \"\"\"\n",
        "        Logs data in each step. Model params and each agent params. Saves it self.log_path at iteration_step key.\n",
        "        :param step: current iteration\n",
        "        \"\"\"\n",
        "        name = 'iteration_' + str(step)\n",
        "        log_dict = self.get_log_data(name)\n",
        "\n",
        "        with open(self.log_path, 'a') as f:\n",
        "            json.dump(log_dict, f)\n",
        "            f.write(os.linesep)\n",
        "\n",
        "    def get_log_data(self, name: str) -> dict:\n",
        "        \"\"\"\n",
        "        Collects data from class fields, throws away unnecessary fields or such that are not easily serializable.\n",
        "        :return: dict with data\n",
        "        \"\"\"\n",
        "        log_dict = defaultdict(dict)\n",
        "        log_dict[name] = deepcopy(vars(self))\n",
        "        log_dict[name].pop('random', None)\n",
        "        log_dict[name].pop('data_dir', None)\n",
        "        log_dict[name].pop('running', None)\n",
        "        log_dict[name].pop('current_id', None)\n",
        "        log_dict[name].pop('experiment_name', None)\n",
        "        log_dict[name].pop('log_path', None)\n",
        "        log_dict[name].pop('schedule', None)\n",
        "        log_dict[name].pop('schedule_Cop', None)\n",
        "        log_dict[name].pop('datacollector', None)\n",
        "        log_dict[name].pop('lookup_corrupt_cops', None)\n",
        "        log_dict[name].pop('citizens_playing', None)\n",
        "        log_dict[name].pop('cops_playing', None)\n",
        "        log_dict[name].pop('logger', None)\n",
        "        if 'iteration_0' != name:\n",
        "            # I'm removing those that shouldn't be changed in later steps or it wouldn't change anything if they were\n",
        "            # rest I left just in case\n",
        "            log_dict[name].pop('_seed', None)\n",
        "            log_dict[name].pop('bribe_amount', None)\n",
        "            log_dict[name].pop('initial_time_left_in_jail', None)\n",
        "            log_dict[name].pop('cost_accept_mean_std', None)\n",
        "            log_dict[name].pop('moral_commitment_mean_std', None)\n",
        "            log_dict[name].pop('fine_amount', None)\n",
        "            log_dict[name].pop('num_citizens', None)\n",
        "            log_dict[name].pop('num_cops', None)\n",
        "            log_dict[name].pop('num_indifferent_cops', None)\n",
        "            log_dict[name].pop('num_corrupted_cops', None)\n",
        "            log_dict[name].pop('num_honest_cops', None)\n",
        "            log_dict[name].pop('num_indifferent_citizens', None)\n",
        "            log_dict[name].pop('num_corrupted_citizens', None)\n",
        "            log_dict[name].pop('num_honest_citizens', None)\n",
        "            log_dict[name].pop('number_of_teams', None)\n",
        "            log_dict[name].pop('corruption_among_teams_spread', None)\n",
        "            log_dict[name].pop('number_of_corrupted_teams', None)\n",
        "            log_dict[name].pop('citizen_complain_memory_discount_factor', None)\n",
        "            log_dict[name].pop('prob_of_prosecution', None)\n",
        "            log_dict[name].pop('memory_size', None)\n",
        "            log_dict[name].pop('cost_complain', None)\n",
        "            log_dict[name].pop('penalty_citizen_prosecution', None)\n",
        "            log_dict[name].pop('rationality_of_agents', None)\n",
        "            log_dict[name].pop('team_size', None)\n",
        "            log_dict[name].pop('jail_time', None)\n",
        "            log_dict[name].pop('jail_cost_factor', None)\n",
        "            log_dict[name].pop('jail_cost', None)\n",
        "            log_dict[name].pop('id_team', None)\n",
        "\n",
        "        # add agents stats\n",
        "        log_dict[name]['citizens'] = {}\n",
        "        log_dict[name]['cops'] = {}\n",
        "\n",
        "        # data_cit = [cit.log_data() for cit in self.schedule.agents]\n",
        "        # action_mean = sum(1 for d in data_cit if d['action'] == 'bribe') / self.num_citizens\n",
        "        \n",
        "\n",
        "\n",
        "        for cit in self.schedule.agents:\n",
        "            log_dict[name]['citizens'][cit.unique_id] = cit.log_data()\n",
        "            if 'iteration_0' != name:\n",
        "                log_dict[name]['citizens'][cit.unique_id].pop('cost_accept', None)\n",
        "\n",
        "        for cop in self.schedule_Cop.agents:\n",
        "            log_dict[name]['cops'][cop.unique_id] = cop.log_data()\n",
        "            if 'iteration_0' != name:\n",
        "                log_dict[name]['cops'][cop.unique_id].pop('moral_commitment', None)\n",
        "        \n",
        "        return log_dict\n",
        "\n",
        "    def get_server_data_collector(self):\n",
        "        return DataCollector(\n",
        "            {\"Prison_Count\": lambda m: sum([1 for cop in self.schedule_Cop.agents if\n",
        "                                            cop.time_left_in_jail > 0]),\n",
        "             \"Bribing\": lambda m: sum([1 for cop in self.schedule_Cop.agents if\n",
        "                                       cop.action == CopActions.bribe]),\n",
        "             \"Not_Bribing\": lambda m: sum([1 for cop in self.schedule_Cop.agents if\n",
        "                                       cop.action == CopActions.not_bribe]),\n",
        "             \"AcceptComplain\": lambda m: sum([1 for cit in self.schedule.agents if\n",
        "                                                cit.action == CitizenActions.accept_complain]),\n",
        "             \"Reject_Complain\": lambda m: sum([1 for cit in self.schedule.agents if\n",
        "                                                cit.action == CitizenActions.reject_complain]),\n",
        "             \"Accept_Silent\": lambda m: sum([1 for cit in self.schedule.agents if\n",
        "                                                cit.action == CitizenActions.accept_silent]),\n",
        "             \"Reject_Silent\": lambda m: sum([1 for cit in self.schedule.agents if\n",
        "                                                cit.action == CitizenActions.reject_silent]),\n",
        "             \"Total Complain\": lambda m: sum([1 for cit in self.schedule.agents if\n",
        "                                                cit.action == CitizenActions.accept_complain or cit.action == CitizenActions.reject_complain]),\n",
        "             \"Total Accept\": lambda m: sum([1 for cit in self.schedule.agents if\n",
        "                                            cit.action == CitizenActions.accept_complain or cit.action == CitizenActions.accept_silent]),\n",
        "             \"Estimated_Prob_Accept\": lambda m: float(np.mean([cop.estimated_prob_accept for cop in self.schedule_Cop.agents])),\n",
        "             \"Estimated_Prob_Caught\": lambda m: float(np.mean([cop.approximate_prob_caught() for cop in self.schedule_Cop.agents])),\n",
        "             \"Complain_Memory\": lambda m: float(np.mean([cit.complain_memory for cit in self.schedule.agents]))})"
      ],
      "metadata": {
        "id": "nxofHSvLAPYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Citizen(Agent):\n",
        "    def __init__(self,\n",
        "                 unique_id,\n",
        "                 model,\n",
        "                 cost_accept_mean_std: Tuple[float, float],\n",
        "                 complain_memory_discount_factor: float,\n",
        "                 prone_to_complain: float = 0.5,\n",
        "                 first_action: str = None\n",
        "                 ):\n",
        "        super().__init__(unique_id, model)\n",
        "\n",
        "        self.action = first_action\n",
        "\n",
        "        # initialize moral costs\n",
        "        self.cost_accept = np.random.normal(loc=cost_accept_mean_std[0], scale=cost_accept_mean_std[1])\n",
        "\n",
        "        # Initialize memory, complain_memory ==0.5 means that the beginning state is being indifferent\n",
        "        self.complain_memory_accumulated_weights = 1\n",
        "        self.complain_memory = prone_to_complain\n",
        "        # 0 is easily forgetting, 1 all events important the same\n",
        "        self.discount_factor = complain_memory_discount_factor\n",
        "\n",
        "        self.possible_actions = CitizenActions\n",
        "\n",
        "    def do_action(self, bribe_amount):\n",
        "        prob_success_complain = self.approximate_prob_successful_complain()\n",
        "\n",
        "        # complain_reward = bribe to make the # of params smaller\n",
        "        utility_accept_complain = -bribe_amount + prob_success_complain * (\n",
        "                bribe_amount - self.model.penalty_citizen_prosecution) - self.model.cost_complain - self.cost_accept\n",
        "        utility_accept_silent = -bribe_amount - self.cost_accept\n",
        "        utility_reject_complain = -self.model.fine_amount - self.model.cost_complain\n",
        "        utility_reject_silent = -self.model.fine_amount\n",
        "\n",
        "        utilities = np.array([utility_accept_complain,\n",
        "                              utility_accept_silent,\n",
        "                              utility_reject_complain,\n",
        "                              utility_reject_silent])\n",
        "\n",
        "        self.action = sample_action(utilities, self.possible_actions, self.model.rationality_of_agents)\n",
        "\n",
        "    def step(self):\n",
        "        self.action = None\n",
        "\n",
        "    def approximate_prob_successful_complain(self):\n",
        "        \"\"\"\n",
        "        Estimate how successful complain will be.\n",
        "        :return: estimated probability of cop being prosecuted.\n",
        "        \"\"\"\n",
        "        return self.complain_memory\n",
        "\n",
        "    def update_successful_complain_memory(self, update):\n",
        "        \"\"\"\n",
        "        Updates running, discounted average. This way doesn't require remembering each event.\n",
        "        Discount factor should be in [0,1] range.\n",
        "         0 is when only last experience is important. 1 - all experiences are weighted the same\n",
        "        :param update: complain event result, 0 - cop is not caught, 1 - cop is caught\n",
        "        \"\"\"\n",
        "        old_complain_memory_sum_weights = self.complain_memory_accumulated_weights\n",
        "        self.complain_memory_accumulated_weights = self.complain_memory_accumulated_weights * self.discount_factor + 1\n",
        "        old_mean_rate = old_complain_memory_sum_weights / self.complain_memory_accumulated_weights\n",
        "\n",
        "        self.complain_memory = self.discount_factor * old_mean_rate * self.complain_memory + update / self.complain_memory_accumulated_weights\n",
        "        assert self.complain_memory <= 1.0 or self.complain_memory >= 0.0, (\n",
        "                \"Complain memory is out of proper range! \" + str(self.complain_memory))\n",
        "\n",
        "    def log_data(self) -> dict:\n",
        "        \"\"\"\n",
        "        Creates a dictionary with all params of this agent\n",
        "        :return: dict with results\n",
        "        \"\"\"\n",
        "\n",
        "        data = {'action': self.action if self.action is None else self.action.name,\n",
        "                'cost_accept': self.cost_accept,\n",
        "                'complain_memory': self.complain_memory}\n",
        "        return data.copy()\n",
        "\n",
        "\n",
        "class Cop(Agent):\n",
        "    def __init__(self, unique_id,\n",
        "                 model,\n",
        "                 time_left_in_jail: int,\n",
        "                 accepted_bribe_memory_size: int,\n",
        "                 bribe_amount: float,\n",
        "                 moral_commitment_mean_std: Tuple[float, float],\n",
        "                 first_action: str = None,\n",
        "                 accepted_bribe_memory_initial: float = 0.5):\n",
        "        super().__init__(unique_id, model)\n",
        "\n",
        "        self.action = first_action\n",
        "        self.bribe_amount = bribe_amount\n",
        "\n",
        "        self.time_left_in_jail = time_left_in_jail\n",
        "        self.accepted_bribe_memory_size = accepted_bribe_memory_size\n",
        "        self.accepted_bribe_memory = [accepted_bribe_memory_initial] * accepted_bribe_memory_size\n",
        "        # for stats\n",
        "        self.estimated_prob_accept = self.approximate_prob_accept()\n",
        "\n",
        "        self.moral_commitment = np.random.normal(loc=moral_commitment_mean_std[0], scale=moral_commitment_mean_std[1])\n",
        "\n",
        "        self.possible_actions = CopActions\n",
        "\n",
        "    def step(self):\n",
        "        self.action = None\n",
        "        # Check whether this cop can play this round\n",
        "        play = self.validate_play()\n",
        "\n",
        "        # If cop can play, chose a random citizen from the available citizens and sample an action for the cop\n",
        "        if play:\n",
        "            self.do_action()\n",
        "            citizen = self.model.get_citizen()\n",
        "\n",
        "            # If the cop bribes, sample an action for the citizen\n",
        "            if self.action == CopActions.bribe:\n",
        "                citizen.do_action(self.bribe_amount)\n",
        "\n",
        "                # If the citizen complains, give the cop a jail time based on the ground truth of the probability of getting caught\n",
        "                if citizen.action in [CitizenActions.accept_complain, CitizenActions.reject_complain]:\n",
        "                    if np.random.multinomial(1,\n",
        "                                             [self.model.prob_of_prosecution,\n",
        "                                              1 - self.model.prob_of_prosecution])[0] == 1:\n",
        "                        # complain succesful -> cop goes to jail\n",
        "                        self.time_left_in_jail = self.model.jail_time\n",
        "                        citizen.update_successful_complain_memory(1)\n",
        "                    else:\n",
        "                        # complain failed, citizen remembers that\n",
        "                        citizen.update_successful_complain_memory(0)\n",
        "                # If the citizen accepts to bribe, update this in the memory for the cop\n",
        "                if citizen.action in [CitizenActions.accept_complain, CitizenActions.accept_silent]:\n",
        "                    self.update_accepting_bribe_memory(1)\n",
        "\n",
        "                # If the citizen rejects to bribe, update this in the memory for the cop\n",
        "                if citizen.action in [CitizenActions.reject_complain, CitizenActions.reject_silent]:\n",
        "                    self.update_accepting_bribe_memory(0)\n",
        "\n",
        "\n",
        "        # If the cop cannot play, check whether the cop is in jail and if the cop is in jail, reduce their sentence by 1\n",
        "        elif self.time_left_in_jail > 0:\n",
        "            self.time_left_in_jail -= 1\n",
        "\n",
        "    def validate_play(self):\n",
        "        \"\"\"\n",
        "        Checks if the cop is allowed to play. They are allowed if they're not in jail. This is checked in model\n",
        "        :return:True if allowed to play\n",
        "        \"\"\"\n",
        "        return True if self in self.model.cops_playing else False\n",
        "\n",
        "    def do_action(self):\n",
        "        \"\"\"\n",
        "        Cop is making an action based on utilities. The sampled action is then saved in the self.action field.\n",
        "        \"\"\"\n",
        "\n",
        "        approx_prob_caught = self.approximate_prob_caught()\n",
        "        approx_prob_accept = self.approximate_prob_accept()\n",
        "\n",
        "        # Calculate expected utilities for each action\n",
        "        utility_bribe = (1 - approx_prob_caught) * approx_prob_accept * self.bribe_amount - approx_prob_caught * self.model.jail_cost\n",
        "        utility_not_bribe = self.moral_commitment\n",
        "\n",
        "        utilities = np.array([utility_bribe, utility_not_bribe])\n",
        "\n",
        "        self.action = sample_action(utilities, self.possible_actions, self.model.rationality_of_agents)\n",
        "\n",
        "    def approximate_prob_caught(self):\n",
        "        \"\"\"\n",
        "        This function checks how many cops in the network/group are currently in jail. This rate is the estimated probability of probability of prosecution\n",
        "        :return: estimated probability of getting caught, 0 to 1\n",
        "        \"\"\"\n",
        "        team = self.model.id_team[self.unique_id]\n",
        "        m = self.model.team_jailed[team]\n",
        "        self.estimated_prob_caught = m / self.model.team_size\n",
        "        return self.estimated_prob_caught\n",
        "\n",
        "    def update_accepting_bribe_memory(self, update):\n",
        "        \"\"\"\n",
        "        Writes the information about last bribing attempt being successful. Keeps the memory in certain size.\n",
        "        :param update: last bribing attempt result. 0 - not successful, 1 - successful\n",
        "        \"\"\"\n",
        "\n",
        "        self.accepted_bribe_memory.append(update)\n",
        "        if len(self.accepted_bribe_memory) > self.accepted_bribe_memory_size:\n",
        "            self.accepted_bribe_memory.pop(0)\n",
        "\n",
        "    def approximate_prob_accept(self):\n",
        "        \"\"\"\n",
        "        Takes the average of the attempts.\n",
        "        :return: estimated probability of accepting the bribe by a citizen\n",
        "        \"\"\"\n",
        "        # saving it here to have it in the logged data\n",
        "        self.estimated_prob_accept = sum(self.accepted_bribe_memory) / self.accepted_bribe_memory_size\n",
        "        return self.estimated_prob_accept\n",
        "\n",
        "    def log_data(self) -> dict:\n",
        "        \"\"\"\n",
        "        Creates a dictionary with all params of this agent\n",
        "        :return: dict with results\n",
        "        \"\"\"\n",
        "\n",
        "        data = {'action': self.action if self.action is None else self.action.name,\n",
        "                'time_left_in_jail': self.time_left_in_jail,\n",
        "                # 'accepted_bribe_memory': self.accepted_bribe_memory.copy(),\n",
        "                'estimated_prob_accept': self.estimated_prob_accept,\n",
        "                'moral_commitment': self.moral_commitment,\n",
        "                'approximated_prob_caught': self.approximate_prob_caught()}\n",
        "        return data"
      ],
      "metadata": {
        "id": "ecoO9tN6BIQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Experiment():\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_params,\n",
        "                 default_params,\n",
        "                 max_steps,\n",
        "                 cop_params,\n",
        "                 cit_params,\n",
        "                 folder):\n",
        "\n",
        "        self.data_params = data_params\n",
        "        self.default_params = default_params\n",
        "        self.max_steps = max_steps\n",
        "        self.cop_params = cop_params\n",
        "        self.cit_params = cit_params\n",
        "        self.folder = folder\n",
        "\n",
        "        self.pair_combinations = list(combinations(self.data_params.keys(), 2))\n",
        "\n",
        "        try:\n",
        "            os.mkdir(self.folder)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    def create_data(self, init_name, init_values):\n",
        "\n",
        "        try:\n",
        "            os.mkdir(self.folder + \"/\" + init_name)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        documentation = []\n",
        "\n",
        "        for param1, param2 in self.pair_combinations:\n",
        "            range_param1, range_param2 = self.data_params[param1], self.data_params[param2]\n",
        "            data_combinations = list(product(range_param1, range_param2))\n",
        "\n",
        "            experiment = []\n",
        "\n",
        "            for setting_param1, setting_param2 in tqdm.tqdm(data_combinations):\n",
        "                test_params = self.default_params.copy()\n",
        "                test_params[param1], test_params[param2] = setting_param1, setting_param2\n",
        "                test_params[\"initial_indifferent_corruption_honest_rate\"] = init_values\n",
        "\n",
        "                model = Corruption(test_params= {param1: setting_param1, param2: setting_param2}, *test_params.values())\n",
        "\n",
        "                start = time.time()\n",
        "                for _ in range(self.max_steps):\n",
        "                    model.step()\n",
        "                end = time.time()\n",
        "                experiment.append(model.datacollector.get_model_vars_dataframe())\n",
        "            \n",
        "            experiment_path = self.folder + \"/\" + init_name + \"/\" + param1 + \"-\" + param2 + \".csv\"\n",
        "            pd.concat(experiment).to_csv(experiment_path, index=False)\n",
        "            documentation.append([experiment_path, param1, param2, range_param1, range_param2, self.max_steps, len(data_combinations)])\n",
        "\n",
        "        pd.DataFrame(documentation, columns=['experiment_path',\n",
        "                                            'param1',\n",
        "                                            'param2',\n",
        "                                            'range_param1',\n",
        "                                            'range_param2',\n",
        "                                            'max_steps',\n",
        "                                            'num_experiments']).to_csv(\"/content/experiment_documentation_\" + init_name + \".csv\", index=False)\n",
        "        shutil.make_archive(init_name, 'zip', self.folder + \"/\" + init_name)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    num_settings = 8\n",
        "    data_params = {\"team_size\": [1, 2, 5, 10, 20, 25, 50, 100][0:num_settings],\n",
        "                   \"corruption_among_teams_spread\": np.linspace(0.0, 0.99, num=num_settings).tolist(),\n",
        "                   \"jail_time\": np.arange(1, num_settings+1).tolist(),\n",
        "                   \"prob_of_prosecution\": np.linspace(0.01, 0.99, num=num_settings).tolist(),\n",
        "                   \"cost_complain\": np.linspace(0.01, 5, num=num_settings).tolist()}\n",
        "\n",
        "    data_params_T = {\"jail_time\": np.arange(1, 5).tolist(),\n",
        "                     \"prob_of_prosecution\": np.linspace(0.01, 0.99, num=4).tolist()}\n",
        "\n",
        "    default_params = {\"num_citizens\": 1000,\n",
        "                      \"num_cops\": 100,\n",
        "                      \"team_size\": 10,\n",
        "                      \"rationality_of_agents\": 10,\n",
        "                      \"jail_time\": 4,\n",
        "                      \"prob_of_prosecution\": 0.7,\n",
        "                      \"memory_size\": 10,\n",
        "                      \"fine_amount\": 1.,\n",
        "                      \"cost_complain\": 0.4,\n",
        "                      \"penalty_citizen_prosecution\": 0.,\n",
        "                      \"jail_cost_factor\": 0.5,\n",
        "                      \"cost_accept_mean_std\": (0.2, 0.05),\n",
        "                      \"citizen_complain_memory_discount_factor\": 0.5,\n",
        "                      \"bribe_amount\": 0.5,\n",
        "                      \"moral_commitment_mean_std\": (0.25, 0.1),\n",
        "                      \"initial_time_left_in_jail\": 0,\n",
        "                      \"initial_indifferent_corruption_honest_rate\": (1.0, 0.0, 0.0),\n",
        "                      \"corruption_among_teams_spread\": 1.0,\n",
        "                      \"logger\": True}\n",
        "\n",
        "    cop_params = ['action', 'time_left_in_jail', 'estimated_prob_accept', 'approximated_prob_caught']\n",
        "    cit_params = ['action', 'complain_memory']\n",
        "\n",
        "    initialisations = {'indifferent': (1.0, 0.0, 0.0),\n",
        "                       'corrupt': (0.0, 1.0, 0.0),\n",
        "                       'honest': (0.0, 0.0, 1.0)}\n",
        "\n",
        "    experiment = Experiment(data_params, default_params, 250, cop_params, cit_params, '/content/results')\n",
        "    for init_name, init_values in initialisations.items():\n",
        "        experiment.create_data(init_name, init_values)"
      ],
      "metadata": {
        "id": "EZdnZFqrBYbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_experiment(documentation_path, vis_param, mode, window):\n",
        "\n",
        "    initialisation = documentation_path.split('.')[0].split('_')[-1]\n",
        "\n",
        "    experiments = pd.read_csv(documentation_path, delimiter = ',')\n",
        "    columns = experiments.columns\n",
        "    experiments_array = experiments.to_numpy()\n",
        "\n",
        "    for experiment in experiments_array:\n",
        "        experiment_path, param1, param2, range_param1, range_param2, max_steps, num_experiments = experiment\n",
        "        experiment_data = pd.read_csv(experiment_path, delimiter = ',')\n",
        "\n",
        "        range_param1 = json.loads(range_param1)\n",
        "        range_param2 = json.loads(range_param2)\n",
        "\n",
        "        #visualize_grid(experiment_data, vis_param, param1, param2, range_param1, range_param2, mode, num_experiments, initialisation)\n",
        "        visualize_graph(experiment_data, vis_param, param1, param2, range_param1, range_param2, num_experiments, window, initialisation)\n",
        "\n",
        "def visualize_graph(experiment_data, vis_param, param1, param2, range_param1, range_param2, num_experiments, window, initialisation):\n",
        "\n",
        "    X = list(range(len(experiment_data)//num_experiments))\n",
        "    Y = []\n",
        "\n",
        "    for bottom in range(0, len(experiment_data), len(experiment_data)//num_experiments):\n",
        "        top = bottom + len(experiment_data)//num_experiments\n",
        "        slice_ = experiment_data.iloc[bottom: top]\n",
        "        slice_2 =  slice_.rolling(window=window).mean()\n",
        "        Y.append(slice_2[\"Bribing\"].values)\n",
        "    \n",
        "    for y in Y:\n",
        "        plt.plot(X, y)\n",
        "\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel(str(vis_param))\n",
        "    plt.title(\"Running average with window=\" + str(window) + '\\n' + \" (\" + param1 + \" and \" + param2 + \")\")\n",
        "    plt.savefig(\"/content/figures/\" + initialisation + \"_graph_\" + param1 + \"_\" + param2  + \".png\", bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def visualize_grid(experiment_data, vis_param, param1, param2, range_param1, range_param2, mode, num_experiments, initialisation):\n",
        "\n",
        "    z = []\n",
        "\n",
        "    for bottom in range(0, len(experiment_data), len(experiment_data)//num_experiments):\n",
        "        top = bottom + len(experiment_data)//num_experiments\n",
        "        slice_ = experiment_data.iloc[bottom: top]\n",
        "        num_active = (slice_[\"Bribing\"] + slice_[\"Not_Bribing\"])\n",
        "        if mode == 'mean':\n",
        "            param_freq = np.mean(slice_[vis_param] / num_active)\n",
        "        if mode == 'percent':\n",
        "            param_freq = np.mean(slice_[vis_param].iloc[int(num_experiments*0.1):] / num_active.iloc[int(num_experiments*0.1):])\n",
        "        if mode == 'median':\n",
        "            param_freq = np.median(slice_[vis_param] / num_active)\n",
        "        \n",
        "        z.append(round(param_freq, 2))\n",
        "\n",
        "    z = np.array(np.split(np.array(z), len(range_param1)))\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(z)\n",
        "\n",
        "    ax.set_xticks(np.arange(len(range_param2)))\n",
        "    ax.set_yticks(np.arange(len(range_param1)))\n",
        "    ax.set_xticklabels([round(item, 2) for item in range_param2])\n",
        "    ax.set_yticklabels([round(item, 2) for item in range_param1])\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "    for i in range(len(range_param1)):\n",
        "        for j in range(len(range_param2)):\n",
        "            text = ax.text(j, i, z[i, j], ha=\"center\", va=\"center\", color=\"b\")\n",
        "\n",
        "    ax.set_title(vis_param)\n",
        "    ax.set_xlabel(param2)\n",
        "    ax.set_ylabel(param1)\n",
        "\n",
        "    fig.tight_layout()\n",
        "\n",
        "    try:\n",
        "        os.mkdir(\"/content/figures\") \n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    plt.savefig(\"/content/figures/\" + initialisation + \"_grid_\" + param1 + \"_\" + param2  + \".png\", bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "read_experiment('/content/experiment_documentation_corrupt.csv', 'Bribing', 'mean', 20)"
      ],
      "metadata": {
        "id": "7pEbDl7FYrG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iPblGi_Uidr8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}